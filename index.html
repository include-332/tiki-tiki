<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI & ML Program Showcase</title>

  <!-- Prism.js for syntax highlighting -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet"/>
  <style>
    body {
      font-family: 'Segoe UI', sans-serif;
      background: #f4f6f8;
      margin: 0;
      padding: 2rem;
      color: #333;
    }

    h1 {
      text-align: center;
      margin-bottom: 2rem;
    }

    .program {
      margin-bottom: 3rem;
    }

    .program-title {
      font-size: 1.2rem;
      font-weight: bold;
      margin-bottom: 0.5rem;
      color: #007bff;
    }

    .code-block {
      position: relative;
    }

    .copy-btn {
      position: absolute;
      top: 10px;
      right: 10px;
      background: #007bff;
      color: white;
      border: none;
      padding: 5px 10px;
      border-radius: 5px;
      cursor: pointer;
      font-size: 0.9rem;
    }

    .copy-btn:hover {
      background: #0056b3;
    }

    pre {
      padding: 1rem;
      border-radius: 10px;
      overflow-x: auto;
      background-color: #2d2d2d;
    }
  </style>
</head>
<body>

  <h1></h1>

  

  <!-- Example Program 1 -->
  <div class="program">
    <div class="program-title">1. Fuzzy Logic Fan Control</div>
    <div class="code-block">
      <button class="copy-btn" onclick="copyCode(this)">Copy</button>
      <pre><code class="language-python">
import skfuzzy as fuzz
from skfuzzy import control as ctrl

temp = ctrl.Antecedent(range(101), 'temperature')
hum = ctrl.Antecedent(range(101), 'humidity')
fan = ctrl.Consequent(range(101), 'fan_speed')
for v in (temp, hum, fan):
    v.automf(3, names=['low', 'medium', 'high'])

fan_ctrl = ctrl.ControlSystem([
    ctrl.Rule(temp['low'] & hum['low'], fan['low']),
    ctrl.Rule(temp['medium'] | hum['medium'], fan['medium']),
    ctrl.Rule(temp['high'] | hum['high'], fan['high'])
])

sim = ctrl.ControlSystemSimulation(fan_ctrl)
sim.inputs({'temperature': 75, 'humidity': 65})
sim.compute()

print("Fan Speed:", sim.output['fan_speed'])
      </code></pre>
    </div>
  </div>
<!-- Example Program 2 -->
  <div class="program">
    <div class="program-title">2. Perceptron Classifier</div>
    <div class="code-block">
      <button class="copy-btn" onclick="copyCode(this)">Copy</button>
      <pre><code class="language-python">
import numpy as np
w,b = np.zeros(2), 0
X,y = np.array([[2,3],[3,2],[1,1],[5,7],[6,8],[7,6]]), [0,0,0,1,1,1]
for _ in range(100):
    for x,t in zip(X,y):
        e = t - int(np.dot(w,x) + b > 0)
        w += 0.1 * e * x
        b += 0.1 * e
for x in np.array([[6,5],[3,2]]):
    print(f"Data {x} belongs to class {int(np.dot(w,x)+b > 0)}")
      </code></pre>
    </div>
  </div>


  <!-- Example Program 2 -->
  <div class="program">
    <div class="program-title">2. Perceptron Classifier (short)</div>
    <div class="code-block">
      <button class="copy-btn" onclick="copyCode(this)">Copy</button>
      <pre><code class="language-python">
import numpy as np
w,b=np.zeros(2),0
X,y=np.array([[2,3],[3,2],[1,1],[5,7],[6,8],[7,6]]),[0,0,0,1,1,1]
for _ in range(100):
 for x,t in zip(X,y):e=t-int(np.dot(w,x)+b>0);w+=0.1*e*x;b+=0.1*e
for x in np.array([[6,5],[3,2]]):print(f"Data {x} belongs to class {int(np.dot(w,x)+b>0)}")
      </code></pre>
    </div>
  </div>


  <!-- Example Program 3 -->
  <div class="program">
    <div class="program-title">3. xor</div>
    <div class="code-block">
      <button class="copy-btn" onclick="copyCode(this)">Copy</button>
      <pre><code class="language-python">
#3.XOR
import numpy as np

def sigmoid(x): return 1 / (1 + np.exp(-x))
def sigmoid_deriv(x): return x * (1 - x)

# XOR dataset
X = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([[0],[1],[1],[0]])

# Architecture
input_size, hidden_size, output_size = 2, 2, 1
W1 = np.random.rand(input_size, hidden_size)
W2 = np.random.rand(hidden_size, output_size)
lr, epochs = 0.1, 10000

# Training loop
for _ in range(epochs):
    h = sigmoid(X @ W1)
    o = sigmoid(h @ W2)
    o_delta = (y - o) * sigmoid_deriv(o)
    h_delta = (o_delta @ W2.T) * sigmoid_deriv(h)
    W2 += h.T @ o_delta * lr
    W1 += X.T @ h_delta * lr

# Output
print("Final predictions:")
for x in X:
    o = sigmoid(sigmoid(x @ W1) @ W2)
    print(f"Input: {x} -> Output: {o[0]:.4f}")
      </code></pre>
    </div>
  </div>


  <!-- Example Program 3 -->
  <div class="program">
    <div class="program-title">2. xor (short)</div>
    <div class="code-block">
      <button class="copy-btn" onclick="copyCode(this)">Copy</button>
      <pre><code class="language-python">
import numpy as np
s=lambda x:1/(1+np.exp(-x))
X,y=np.array([[0,0],[0,1],[1,0],[1,1]]),np.array([[0],[1],[1],[0]])
W1,W2=np.random.rand(2,2),np.random.rand(2,1)
for _ in range(10000):h=s(X@W1);W2+=h.T@((y-s(h@W2))*(h2:=s(h@W2))*(1-h2))*0.1;W1+=X.T@((y-h2)@W2.T*h*(1-h))*0.1
print("Final predictions:")
for x in X:print(f"Input: {x} -> Output: {s(s(x@W1)@W2)[0]:.4f}")
      </code></pre>
    </div>
  </div>



    <!-- Example Program 4 -->
  <div class="program">
    <div class="program-title">4. Self-organising map</div>
    <div class="code-block">
      <button class="copy-btn" onclick="copyCode(this)">Copy</button>
      <pre><code class="language-python">

import numpy as np
import matplotlib.pyplot as plt

# Generate random 2D data
np.random.seed(42)
data = np.random.rand(100, 2)

# SOM parameters
grid_x, grid_y = 10, 10
input_dim = 2
learning_rate = 0.2
epochs = 1000

# Initialize weights randomly for each neuron in the grid
weights = np.random.rand(grid_x, grid_y, input_dim)

# Train the SOM
for epoch in range(epochs):
    for sample in data:
        # Find Best Matching Unit (BMU)
        dists = np.linalg.norm(weights - sample, axis=2)
        bmu_x, bmu_y = np.unravel_index(np.argmin(dists), (grid_x, grid_y))

        # Update weights based on distance to BMU
        for i in range(grid_x):
            for j in range(grid_y):
                dist_to_bmu = np.linalg.norm([i - bmu_x, j - bmu_y])
                influence = np.exp(-dist_to_bmu**2 / (2 * (epoch + 1)**2))
                weights[i, j] += influence * learning_rate * (sample - weights[i, j])

# Assign clusters (map neurons to closest data point index)
cluster_map = np.zeros((grid_x, grid_y), dtype=int)
for i in range(grid_x):
    for j in range(grid_y):
        dists = np.linalg.norm(data - weights[i, j], axis=1)
        cluster_map[i, j] = np.argmin(dists)

# Plot results
plt.figure(figsize=(8, 8))
plt.pcolormesh(cluster_map, cmap='viridis')
plt.colorbar(label='Closest Data Point Index')
plt.scatter(data[:, 0] * grid_x, data[:, 1] * grid_y, color='red', label='Data points')
plt.title('Self-Organizing Map (SOM)')
plt.legend()
plt.show()
      </code></pre>
    </div>
  </div>



  <!-- Example Program 4 -->
  <div class="program">
    <div class="program-title">4. Self-organising map (short)</div>
    <div class="code-block">
      <button class="copy-btn" onclick="copyCode(this)">Copy</button>
      <pre><code class="language-python">
import numpy as np
import matplotlib.pyplot as plt

# Generate data and initialize SOM
d = np.random.rand(100, 2)
w = np.random.rand(10, 10, 2)

# Train SOM
for e in range(1000):
    for x in d:
        b = np.unravel_index(np.argmin(np.linalg.norm(w - x, axis=2)), (10, 10))
        for i in range(10):
            for j in range(10):
                w[i,j] += np.exp(-np.linalg.norm([i-b[0],j-b[1]])**2/(2*(e+1)**2)) * 0.2 * (x-w[i,j])

# Create cluster map
c = np.array([[np.argmin(np.linalg.norm(d-w[i,j], axis=1)) for j in range(10)] for i in range(10)])

# Plot results
plt.pcolormesh(c, cmap='viridis')
plt.colorbar()
plt.scatter(d[:,0]*10, d[:,1]*10, c='r')
plt.show()
      </code></pre>
    </div>
  </div>



    <!-- Example Program 5 -->
  <div class="program">
    <div class="program-title">5.Maximization FUn</div>
    <div class="code-block">
      <button class="copy-btn" onclick="copyCode(this)">Copy</button>
      <pre><code class="language-python">

import random

# Fitness function: quadratic with a max, adjusted to avoid negative values
def fitness(x):
    return -(x**2) + 6*x + 9  # Your original fitness function (still can be negative)

def genetic_algo(generations=5, population_size=100, low=-10, high=10):
    # Initialize population
    population = [random.uniform(low, high) for _ in range(population_size)]

    for gen in range(generations):
        # Calculate fitness for all individuals
        fitness_scores = [fitness(x) for x in population]

        # Adjust fitness to ensure it's always positive (or set a minimum value)
        total_fitness = sum(fitness_scores)

        # Ensure the total fitness is positive
        if total_fitness <= 0:
            print(f"Total fitness at generation {gen+1} is zero or negative, adjusting fitness.")
            fitness_scores = [score + abs(min(fitness_scores)) + 1 for score in fitness_scores]  # Ensure positive fitness

        selected = random.choices(population, weights=fitness_scores, k=population_size)

        # Crossover and mutation
        new_population = []
        for i in range(0, population_size, 2):
            p1, p2 = selected[i], selected[i + 1]
            # Crossover
            child = (p1 + p2) /.  2 if random.random() < 0.7 else p1
            # Mutation
            if random.random() < 0.01:
                child += random.uniform(-1, 1)
            new_population += [child, child]  # Maintain population size

        population = new_population[:population_size]

        # Find best individual in current generation
        best = max(population, key=fitness)
        print(f"Gen {gen+1}: Best = {best:.4f}, Fitness = {fitness(best):.4f}")

    return max(population, key=fitness)

# Run the genetic algorithm
best_solution = genetic_algo()
print(f"\nBest solution: {best_solution:.4f}, Fitness: {fitness(best_solution):.4f}")
      </code></pre>
    </div>
  </div>


  <!-- Example Program 5 -->
  <div class="program">
    <div class="program-title">5. Maximization FUn (short)</div>
    <div class="code-block">
      <button class="copy-btn" onclick="copyCode(this)">Copy</button>
      <pre><code class="language-python">
import random

f=lambda x:-x**2+6*x+9
def g(g=5,n=100,l=-10,h=10):
 p=[random.uniform(l,h)for _ in range(n)]
 for i in range(g):
  s=[f(x)for x in p]
  if sum(s)<=0:print(f"Total fitness at generation {i+1} is zero or negative, adjusting fitness.");s=[x+abs(min(s))+1 for x in s]
  m=random.choices(p,weights=s,k=n)
  p=[(a+b)/2 if random.random() < 0.7 else a for a,b in zip(m[::2],m[1::2])]
  p=[x+random.uniform(-1,1) if random.random()< 0.01 else x for x in p 
  b=max(p,key=f);print(f"Gen {i+1}: Best = {b:.4f}, Fitness = {f(b):.4f}")
 return max(p,key=f)

b=g()
print(f"\nBest solution: {b:.4f}, Fitness: {f(b):.4f}")
      </code></pre>
    </div>
  </div>



  <!-- Example Program 6 -->
  <div class="program">
    <div class="program-title"> 6. Two Ip Sine Fun</div>
    <div class="code-block">
      <button class="copy-btn" onclick="copyCode(this)">Copy</button>
      <pre><code class="language-python">

import numpy as np
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Generate 2D input grid and target output
x = np.linspace(0, 2 * np.pi, 100)
X, Y = np.meshgrid(x, x)
Z = np.sin(X) * np.sin(Y)

# Prepare dataset for training
inputs = np.column_stack((X.ravel(), Y.ravel()))
targets = Z.ravel()

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.2, random_state=42)

# Train MLP Regressor
model = MLPRegressor(hidden_layer_sizes=(10,), max_iter=1000, random_state=42)
model.fit(X_train, y_train)

# Predict and evaluate
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse:.4f}")

# Plot actual vs predicted
fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(X_test[:, 0], X_test[:, 1], y_test, color='red', label='Actual')
ax.scatter(X_test[:, 0], X_test[:, 1], y_pred, color='blue', alpha=0.6, label='Predicted')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
ax.set_title('MLP Approximation of sin(x) * sin(y)')
ax.legend()
plt.show()

      </code></pre>
    </div>
  </div>


  <!-- Example Program 6 -->
  <div class="program">
    <div class="program-title">6. Two Ip Sine Fun (short)</div>
    <div class="code-block">
      <button class="copy-btn" onclick="copyCode(this)">Copy</button>
      <pre><code class="language-python">
import numpy as np
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Generate data
x = np.linspace(0, 2*np.pi, 100)
X, Y = np.meshgrid(x, x)
Z = np.sin(X) * np.sin(Y)
inputs = np.column_stack((X.ravel(), Y.ravel()))
targets = Z.ravel()

# Train model
X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.2)
model = MLPRegressor(hidden_layer_sizes=(10,), max_iter=1000).fit(X_train, y_train)

# Evaluate
y_pred = model.predict(X_test)
print(f"MSE: {np.mean((y_test-y_pred)**2):.4f}")

# Plot
ax = plt.figure().add_subplot(111, projection='3d')
ax.scatter(X_test[:,0], X_test[:,1], y_test, c='r', label='Actual')
ax.scatter(X_test[:,0], X_test[:,1], y_pred, c='b', alpha=0.5, label='Predicted')
ax.legend()
plt.show()
      </code></pre>
    </div>
  </div>




  <!-- Example Program 7 -->
  <div class="program">
    <div class="program-title">7. Three Input Non-linear</div>
    <div class="code-block">
      <button class="copy-btn" onclick="copyCode(this)">Copy</button>
      <pre><code class="language-python">

import random, math

# Fitness function (Rastrigin)
def fitness(x, y, z):
    return -(x**2 + y**2 + z**2) + 10 * (math.cos(2*math.pi*x) + math.cos(2*math.pi*y) + math.cos(2*math.pi*z))

# Initialize population
def init_population(size, low, high):
    return [(random.uniform(low, high), random.uniform(low, high), random.uniform(low, high)) for _ in range(size)]

# Roulette wheel selection
def select(pop):
    fits = [fitness(*ind) for ind in pop]
    total = sum(fits)
    probs = [f / total for f in fits]
    return random.choices(pop, weights=probs, k=2)

# Crossover (blended)
def crossover(p1, p2, prob=0.7):
    if random.random() < prob:
        alpha = random.random()
        return tuple(alpha * a + (1 - alpha) * b for a, b in zip(p1, p2)), \
               tuple(alpha * b + (1 - alpha) * a for a, b in zip(p1, p2))
    return p1, p2

# Mutation
def mutate(ind, prob=0.01):
    return tuple(g + random.uniform(-0.1, 0.1) if random.random() < prob else g for g in ind)

# Main GA loop
def run_ga(generations=5, size=100, low=-1, high=1):
    pop = init_population(size, low, high)
    for gen in range(generations):
        new_pop = []
        while len(new_pop) < size:
            p1, p2 = select(pop)
            c1, c2 = crossover(p1, p2)
            new_pop.extend([mutate(c1), mutate(c2)])
        pop = new_pop[:size]
        best = max(pop, key=lambda ind: fitness(*ind))
        print(f"Gen {gen+1}: Best {best}, Fitness: {fitness(*best):.4f}")
    return best

if __name__ == "__main__":
    best = run_ga()
    print(f"\nBest solution: {best}, Fitness: {fitness(*best):.4f}")

      </code></pre>
    </div>
  </div>


  <!-- Example Program 7 -->
  <div class="program">
    <div class="program-title">7. Three Input Non-linear (short)</div>
    <div class="code-block">
      <button class="copy-btn" onclick="copyCode(this)">Copy</button>
      <pre><code class="language-python">
import random, math

f=lambda x,y,z:-(x*x+y*y+z*z)+10*(math.cos(6.283*x)+math.cos(6.283*y)+math.cos(6.283*z))
def r(g=5,s=100,l=-1,h=1):
 p=[(random.uniform(l,h),random.uniform(l,h),random.uniform(l,h))for _ in range(s)]
 for i in range(g):
  fs=[f(*x)for x in p]
  if sum(fs)<=0:fs=[f+abs(min(fs))+1 for f in fs]
  p=[tuple(a+random.uniform(-.1,.1)if random.random()<.01 else a for a in random.choices(p,weights=fs,k=1)[0])]
  c=max(p,key=lambda x:f(*x))
  print(f"Gen {i+1}: Best {tuple(round(v,4)for v in c)}, Fitness: {f(*c):.4f}")
 return max(p,key=lambda x:f(*x))

best=r()
print(f"\nBest solution: {tuple(round(v,4)for v in best)}, Fitness: {f(*best):.4f}")
      </code></pre>
    </div>
  </div>
  <!-- ⚠️ Repeat for Programs 3 to 12 by copying and modifying the above blocks -->

  <!-- Prism and copy script -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
  <script>
    function copyCode(button) {
      const code = button.nextElementSibling.innerText;
      navigator.clipboard.writeText(code).then(() => {
        button.innerText = 'Copied!';
        setTimeout(() => (button.innerText = 'Copy'), 2000);
      });
    }
  </script>

</body>
</html>
